library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(beeswarm)
library(tokenizers)
library(ggplot2)
library(plotly)
library(DT)
library(qdap)
library(syuzhet)
library(topicmodels)
#load data
info <- read.xlsx("../data/InaugurationInfo.xlsx",1)
date.file <- read.table("../data/InauguationDates.txt", header=F, sep='\t', fill=T)
#using 'date.file' to generate a 'date.vec1' about time
date.vec1 <- NULL
for(i in 2:nrow(date.file)){
for(j in 2:ncol(date.file)){
date.vec1 <- c(date.vec1,as.character(date.file[i,j]))
}
}
date.vec1 <- date.vec1[!(date.vec1 == "")]
#using 'date.file' to generate a 'date.vec2' about president
date.vec2 <- NULL
for(i in 2:nrow(date.file)){
n <- sum(date.file[i,2:5] != "")
date.vec2 <- c(date.vec2,rep(as.character(date.file[i,1]),n))
}
#using 'date.file' to generate a 'date.vec3' about term
date.vec3 <- NULL
for(i in 2:nrow(date.file)){
n <- sum(date.file[i,2:5] != "")
date.vec3 <- c(date.vec3,c(1:n))
}
#combine 'date.vec1' and 'date.vec2' and 'date.vec3' into 'date'
date <- cbind(date.vec1,date.vec2,date.vec3)
date <- as.data.frame(date)
names(date) <- c("Time","President","Term")
setwd("C:/Users/dingx/Documents/GitHub/Spring2018-Project1-XueyingDing/data/InauguralSpeeches")
#generate a 'speech.vec1' about speech
speech.vec1 <- NULL
for(i in 1:58){
file <- readLines(list.files()[i])
file <- paste(file,collapse = "")
speech.vec1 <- c(speech.vec1,file)
}
#generate a 'speech.vec2' about president
#generate a 'speech.vec3' about term
speech.vec2 <- NULL
speech.vec3 <- NULL
for(i in 1:58){
text.name <- list.files()[i]
president <- substring(text.name,6,nchar(text.name)-6)
term <- substring(text.name,nchar(text.name)-4,nchar(text.name)-4)
term <- as.numeric(term)
speech.vec2 <- c(speech.vec2,president)
speech.vec3 <- c(speech.vec3,term)
}
#combine 'speech.vec1' and 'speech.vec2' and 'speech.vec3' into 'speech'
speech <- cbind(speech.vec1,speech.vec2,speech.vec3)
speech <- as.data.frame(speech)
names(speech) <- c("Speech","President","Term")
speech$Term <- as.numeric(speech$Term)
speech$President <- as.character(speech$President)
speech$Speech <- as.character(speech$Speech)
date$Term <- as.numeric(date$Term)
date$President <- as.character(date$President)
info$President <- as.character(info$President)
#combine 'info' and 'date' and 'speech' into a new data frame 'mydata'
mydata <- info %>%
left_join(date,by = c("President","Term"))
mydata <- merge(mydata,speech,by.x = c("File","Term"),by.y = c("President","Term"))
#sort 'data' by time
mydata$Time <- as.Date(mydata$Time, format="%m/%d/%Y")
mydata <- mydata[order(mydata$Time),]
#create 'word_cloud' function
word_cloud <- function(article){
docs <- Corpus(VectorSource(article))
#text transformation
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
#clean the text
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#Generate the Word cloud
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "BuGn"))
}
#create 'top10.word' function
top10.word <- function(article){
docs <- Corpus(VectorSource(article))
#text transformation
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
#clean the text
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
#docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
####d <- data.frame(word = names(v),freq=v)
d <- data.frame(word = names(v))
return(head(d,10))
}
par(mfrow=c(1,2),mar = c(3, 0, 2, 0))
party <- unique(mydata$Party)
mytext <- paste(mydata$Speech[mydata$Party == party[4]],collapse = "")
word_cloud(mytext)
# par(mfrow=c(3,2))
# party <- unique(mydata$Party)
# for(i in 1:length(party)){
#   mytext <- paste(mydata$Speech[mydata$Party == party[i]],collapse = "")
#   word_cloud(mytext)
#   title(main = as.character(party[i]))
# }
par(mfrow=c(1,2),mar = c(3, 0, 2, 0))
party <- unique(mydata$Party)
mytext <- paste(mydata$Speech[mydata$Party == party[4]],collapse = "")
word_cloud(mytext)
#install.packages("xlsx")
#install.packages("rJava")
#install.packages("xlsxjars")
library(rJava)
library(xlsxjars)
library(xlsx)
library(dplyr)
info <- read.xlsx("../data/InaugurationInfo.xlsx",1)
date.file <- read.table("../data/InauguationDates.txt", header=F, sep='\t', fill=T)
#using 'date.file' to generate a 'date.vec1' about time
date.vec1 <- NULL
for(i in 2:nrow(date.file)){
for(j in 2:ncol(date.file)){
date.vec1 <- c(date.vec1,as.character(date.file[i,j]))
}
}
date.vec1 <- date.vec1[!(date.vec1 == "")]
#using 'date.file' to generate a 'date.vec2' about president
date.vec2 <- NULL
for(i in 2:nrow(date.file)){
n <- sum(date.file[i,2:5] != "")
date.vec2 <- c(date.vec2,rep(as.character(date.file[i,1]),n))
}
#using 'date.file' to generate a 'date.vec3' about term
date.vec3 <- NULL
for(i in 2:nrow(date.file)){
n <- sum(date.file[i,2:5] != "")
date.vec3 <- c(date.vec3,c(1:n))
}
#combine 'date.vec1' and 'date.vec2' and 'date.vec3' into 'date'
date <- cbind(date.vec1,date.vec2,date.vec3)
date <- as.data.frame(date)
names(date) <- c("Time","President","Term")
setwd("C:/Users/dingx/Documents/GitHub/Spring2018-Project1-XueyingDing/data/InauguralSpeeches")
#generate a 'speech.vec1' about speech
speech.vec1 <- NULL
for(i in 1:58){
file <- readLines(list.files()[i])
file <- paste(file,collapse = "")
speech.vec1 <- c(speech.vec1,file)
}
#generate a 'speech.vec2' about president
#generate a 'speech.vec3' about term
speech.vec2 <- NULL
speech.vec3 <- NULL
for(i in 1:58){
text.name <- list.files()[i]
president <- substring(text.name,6,nchar(text.name)-6)
term <- substring(text.name,nchar(text.name)-4,nchar(text.name)-4)
term <- as.numeric(term)
speech.vec2 <- c(speech.vec2,president)
speech.vec3 <- c(speech.vec3,term)
}
#combine 'speech.vec1' and 'speech.vec2' and 'speech.vec3' into 'speech'
speech <- cbind(speech.vec1,speech.vec2,speech.vec3)
speech <- as.data.frame(speech)
names(speech) <- c("Speech","President","Term")
speech$Term <- as.numeric(speech$Term)
speech$President <- as.character(speech$President)
speech$Speech <- as.character(speech$Speech)
date$Term <- as.numeric(date$Term)
date$President <- as.character(date$President)
info$President <- as.character(info$President)
#combine 'info' and 'date' and 'speech' into a new data frame 'mydata'
mydata <- info %>%
left_join(date,by = c("President","Term"))
mydata <- merge(mydata,speech,by.x = c("File","Term"),by.y = c("President","Term"))
#sort 'data' by time
mydata$Time <- as.Date(mydata$Time, format="%m/%d/%Y")
mydata <- mydata[order(mydata$Time),]
#install.packages("tm")
#install.packages("NLP")
#install.packages("wordcloud")
#install.packages("RColorBrewer")
#install.packages("tidytext")
#install.packages("DT")
library(tidytext)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(DT)
#  "http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know#the-5-main-steps-to-create-word-clouds-in-r"
# # Load the data as a corpus
# docs <- Corpus(VectorSource(text))
#
#
# #text transformation
# toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
# docs <- tm_map(docs, toSpace, "/")
# docs <- tm_map(docs, toSpace, "@")
# docs <- tm_map(docs, toSpace, "\\|")
#
# #clean the text
# # Convert the text to lower case
# docs <- tm_map(docs, content_transformer(tolower))
# # Remove numbers
# docs <- tm_map(docs, removeNumbers)
# # Remove english common stopwords
# docs <- tm_map(docs, removeWords, stopwords("english"))
# # Remove your own stop word
# # specify your stopwords as a character vector
# docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# # Remove punctuations
# docs <- tm_map(docs, removePunctuation)
# # Eliminate extra white spaces
# docs <- tm_map(docs, stripWhitespace)
# # Text stemming
# docs <- tm_map(docs, stemDocument)
#
# #Build a term-document matrix
# dtm <- TermDocumentMatrix(docs)
# m <- as.matrix(dtm)
# v <- sort(rowSums(m),decreasing=TRUE)
# d <- data.frame(word = names(v),freq=v)
# head(d,10)
#
# # #Generate the Word cloud
# # set.seed(1234)
# # wordcloud(words = d$word, freq = d$freq, min.freq = 1,
# #           max.words=200, random.order=FALSE, rot.per=0.35,
# #           colors=brewer.pal(8, "Dark2"))
word_cloud <- function(article){
docs <- Corpus(VectorSource(article))
#text transformation
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
#clean the text
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#Generate the Word cloud
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "BuGn"))
}
top10.word <- function(article){
docs <- Corpus(VectorSource(article))
#text transformation
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
#clean the text
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
#docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
####d <- data.frame(word = names(v),freq=v)
d <- data.frame(word = names(v))
return(head(d,10))
}
# par(mfrow=c(3,2))
# party <- unique(mydata$Party)
# for(i in 1:length(party)){
#   mytext <- paste(mydata$Speech[mydata$Party == party[i]],collapse = "")
#   word_cloud(mytext)
#   title(main = as.character(party[i]))
# }
par(mfrow=c(1,2),mar = c(3, 0, 2, 0))
party <- unique(mydata$Party)
mytext <- paste(mydata$Speech[mydata$Party == party[4]],collapse = "")
word_cloud(mytext)
title(main = as.character(party[4]))
mytext <- paste(mydata$Speech[mydata$Party == party[6]],collapse = "")
word_cloud(mytext)
title(main = as.character(party[6]))
library(rJava)
library(xlsxjars)
library(xlsx)
library(dplyr)
library(tidytext)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(beeswarm)
library(tokenizers)
library(ggplot2)
library(plotly)
library(DT)
library(qdap)
library(syuzhet)
library(topicmodels)
#load data
info <- read.xlsx("../data/InaugurationInfo.xlsx",1)
date.file <- read.table("../data/InauguationDates.txt", header=F, sep='\t', fill=T)
#using 'date.file' to generate a 'date.vec1' about time
date.vec1 <- NULL
for(i in 2:nrow(date.file)){
for(j in 2:ncol(date.file)){
date.vec1 <- c(date.vec1,as.character(date.file[i,j]))
}
}
date.vec1 <- date.vec1[!(date.vec1 == "")]
#using 'date.file' to generate a 'date.vec2' about president
date.vec2 <- NULL
for(i in 2:nrow(date.file)){
n <- sum(date.file[i,2:5] != "")
date.vec2 <- c(date.vec2,rep(as.character(date.file[i,1]),n))
}
#using 'date.file' to generate a 'date.vec3' about term
date.vec3 <- NULL
for(i in 2:nrow(date.file)){
n <- sum(date.file[i,2:5] != "")
date.vec3 <- c(date.vec3,c(1:n))
}
#combine 'date.vec1' and 'date.vec2' and 'date.vec3' into 'date'
date <- cbind(date.vec1,date.vec2,date.vec3)
date <- as.data.frame(date)
names(date) <- c("Time","President","Term")
setwd("C:/Users/dingx/Documents/GitHub/Spring2018-Project1-XueyingDing/data/InauguralSpeeches")
#generate a 'speech.vec1' about speech
speech.vec1 <- NULL
for(i in 1:58){
file <- readLines(list.files()[i])
file <- paste(file,collapse = "")
speech.vec1 <- c(speech.vec1,file)
}
#generate a 'speech.vec2' about president
#generate a 'speech.vec3' about term
speech.vec2 <- NULL
speech.vec3 <- NULL
for(i in 1:58){
text.name <- list.files()[i]
president <- substring(text.name,6,nchar(text.name)-6)
term <- substring(text.name,nchar(text.name)-4,nchar(text.name)-4)
term <- as.numeric(term)
speech.vec2 <- c(speech.vec2,president)
speech.vec3 <- c(speech.vec3,term)
}
#combine 'speech.vec1' and 'speech.vec2' and 'speech.vec3' into 'speech'
speech <- cbind(speech.vec1,speech.vec2,speech.vec3)
speech <- as.data.frame(speech)
names(speech) <- c("Speech","President","Term")
speech$Term <- as.numeric(speech$Term)
speech$President <- as.character(speech$President)
speech$Speech <- as.character(speech$Speech)
date$Term <- as.numeric(date$Term)
date$President <- as.character(date$President)
info$President <- as.character(info$President)
#combine 'info' and 'date' and 'speech' into a new data frame 'mydata'
mydata <- info %>%
left_join(date,by = c("President","Term"))
mydata <- merge(mydata,speech,by.x = c("File","Term"),by.y = c("President","Term"))
#sort 'data' by time
mydata$Time <- as.Date(mydata$Time, format="%m/%d/%Y")
mydata <- mydata[order(mydata$Time),]
#create 'word_cloud' function
word_cloud <- function(article){
docs <- Corpus(VectorSource(article))
#text transformation
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
#clean the text
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#Generate the Word cloud
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "BuGn"))
}
#create 'top10.word' function
top10.word <- function(article){
docs <- Corpus(VectorSource(article))
#text transformation
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
#clean the text
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
#docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
####d <- data.frame(word = names(v),freq=v)
d <- data.frame(word = names(v))
return(head(d,10))
}
par(mfrow=c(1,2),mar = c(3, 0, 2, 0))
party <- unique(mydata$Party)
mytext <- paste(mydata$Speech[mydata$Party == party[4]],collapse = "")
word_cloud(mytext)
